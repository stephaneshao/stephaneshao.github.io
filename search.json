[{"authors":["S. Shao"],"categories":null,"content":"","date":1670889600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670889600,"objectID":"52ccbaf57c904c0022a8ce7ecaee9740","permalink":"https://stephaneshao.github.io/publication/codeascraft_04_winners_curse/","publishdate":"2022-12-13T00:00:00Z","relpermalink":"/publication/codeascraft_04_winners_curse/","section":"publication","summary":"","tags":[],"title":"Mitigating the winner’s curse in online experiments","type":"publication"},{"authors":["S. Shao","C. Burke"],"categories":null,"content":"","date":1670371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1670371200,"objectID":"4fc6c234f34185308feeda8409477e51","permalink":"https://stephaneshao.github.io/publication/codeascraft_03_persistent_exps/","publishdate":"2022-12-07T00:00:00Z","relpermalink":"/publication/codeascraft_03_persistent_exps/","section":"publication","summary":"","tags":[],"title":"Understanding the collective impact of experiments","type":"publication"},{"authors":["S. Shao","L. Ignatovsky","J. Beckley"],"categories":null,"content":"","date":1646352000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646352000,"objectID":"cd0bf004808265daac4b63d271df2893","permalink":"https://stephaneshao.github.io/publication/codeascraft_02_imbalance/","publishdate":"2022-03-04T00:00:00Z","relpermalink":"/publication/codeascraft_02_imbalance/","section":"publication","summary":"","tags":[],"title":"Imbalance detection for healthier experimentation","type":"publication"},{"authors":["S. Shao","K. Gaan","S. Emanuele","J. Kaushik"],"categories":null,"content":"","date":1622505600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1622505600,"objectID":"574a714b427c509992ee7fb786785d2c","permalink":"https://stephaneshao.github.io/publication/codeascraft_01_cuped/","publishdate":"2021-06-01T00:00:00Z","relpermalink":"/publication/codeascraft_01_cuped/","section":"publication","summary":"","tags":[],"title":"Increasing experimentation accuracy and speed by using control variates","type":"publication"},{"authors":["Z. Branson","S. Shao"],"categories":null,"content":"","date":1609459200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609459200,"objectID":"c940eef804acd2d1531060b489f4728a","permalink":"https://stephaneshao.github.io/publication/ridgererand/","publishdate":"2021-01-01T00:00:00Z","relpermalink":"/publication/ridgererand/","section":"publication","summary":"Randomization ensures that observed and unobserved covariates are balanced, on average. However, randomizing units to treatment and control often leads to covariate imbalances in realization, and such imbalances can inflate the variance of estimators of the treatment effect. One solution to this problem is rerandomization---an experimental design strategy that randomizes units until some balance criterion is fulfilled---which yields more precise estimators of the treatment effect if covariates are correlated with the outcome. Most rerandomization schemes in the literature utilize the Mahalanobis distance, which may not be preferable when covariates are correlated or vary in importance. As an alternative, we introduce an experimental design strategy called ridge rerandomization, which utilizes a modified Mahalanobis distance that addresses collinearities among covariates and automatically places a hierarchy of importance on the covariates according to their eigenstructure. This modified Mahalanobis distance has connections to principal components and the Euclidean distance, and---to our knowledge---has remained unexplored. We establish several theoretical properties of this modified Mahalanobis distance and our ridge rerandomization scheme. These results guarantee that ridge rerandomization is preferable over randomization and suggest when ridge rerandomization is preferable over standard rerandomization schemes.  We also provide simulation evidence that suggests that ridge rerandomization is particularly preferable over typical rerandomization schemes in high-dimensional or high-collinearity settings.","tags":[],"title":"Ridge rerandomization: an experimental design strategy in the presence of covariate collinearity","type":"publication"},{"authors":["S. Shao"],"categories":null,"content":"","date":1559260800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1559260800,"objectID":"1d22df943bb32ebec8b16981bee0bdbf","permalink":"https://stephaneshao.github.io/publication/dissertation/","publishdate":"2019-05-31T00:00:00Z","relpermalink":"/publication/dissertation/","section":"publication","summary":"This thesis studies the implementation and properties of a novel criterion for model comparison, with a keen interest in the task of selecting Bayesian state-space models. This criterion, based on the Hyvärinen score and termed the H-factor, was recently advocated in the decision-theoretic literature as an appealing alternative to the ubiquitous Bayes factor, particularly in settings where the presence of vague prior distributions renders the latter unreliable. The practical use of H-factors requires them to be numerically estimated, which we propose to consistently achieve by using sequential Monte Carlo methods. The uncertainty of the model choice, resulting from this estimation, is quantified by using new advances in unbiased Markov chain Monte Carlo methods to construct confidence intervals for the exact H-factors. Proving theoretical guarantees for this new criterion in large samples will bring us to the realm of Bayesian asymptotics. It will require us to look into the consistency and asymptotic Normality of posterior distributions, à la Bernstein-von Mises, in general and possibly misspecified state-space models.","tags":[],"title":"Bayesian model comparison and asymptotics for state-space models","type":"publication"},{"authors":["S. Shao","P. E. Jacob","J. Ding","V. Tarokh"],"categories":null,"content":"","date":1553472000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1553472000,"objectID":"daddd586d916b00a4fd8923100c4b48e","permalink":"https://stephaneshao.github.io/publication/hyvarinen/","publishdate":"2019-03-25T00:00:00Z","relpermalink":"/publication/hyvarinen/","section":"publication","summary":"The Bayes factor is a widely used criterion in model comparison and its logarithm is a difference of out-of-sample predictive scores under the logarithmic scoring rule. However, when some of the candidate models involve vague priors on their parameters, the log-Bayes factor features an arbitrary additive constant that hinders its interpretation. As an alternative, we consider model comparison using the Hyvärinen score. We propose a method to consistently estimate this score for parametric models, using sequential Monte Carlo methods. We show that this score can be estimated for models with tractable likelihoods as well as nonlinear non-Gaussian state-space models with intractable likelihoods. We prove the asymptotic consistency of this new model selection criterion under strong regularity assumptions in the case of non-nested models, and we provide qualitative insights for the nested case. We also use existing characterizations of proper scoring rules on discrete spaces to extend the Hyvärinen score to discrete observations. Our numerical illustrations include Lévy-driven stochastic volatility models and diffusion models for population dynamics.","tags":[],"title":"Bayesian model comparison with the Hyvärinen score: computation and consistency","type":"publication"}]